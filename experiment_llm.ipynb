{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae19827-9e14-4abc-b4a3-5918be0b3662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlamaTokenizer, LlamaForCausalLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mLlamaTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mChanceFocus/finma-7b-full\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m model = LlamaForCausalLM.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mChanceFocus/finma-7b-full\u001b[39m\u001b[33m'\u001b[39m, device_map=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2013\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2010\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2011\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2013\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2016\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2017\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2259\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._from_pretrained\u001b[39m\u001b[34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2257\u001b[39m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[32m   2258\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2259\u001b[39m     tokenizer = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[32m   2261\u001b[39m     logger.info(\n\u001b[32m   2262\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2263\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2264\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py:171\u001b[39m, in \u001b[36mLlamaTokenizer.__init__\u001b[39m\u001b[34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.add_eos_token = add_eos_token\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.use_default_system_prompt = use_default_system_prompt\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28mself\u001b[39m.sp_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_spm_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrom_slow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.add_prefix_space = add_prefix_space\n\u001b[32m    174\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    175\u001b[39m     bos_token=bos_token,\n\u001b[32m    176\u001b[39m     eos_token=eos_token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     **kwargs,\n\u001b[32m    188\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py:198\u001b[39m, in \u001b[36mLlamaTokenizer.get_spm_processor\u001b[39m\u001b[34m(self, from_slow)\u001b[39m\n\u001b[32m    196\u001b[39m tokenizer = spm.SentencePieceProcessor(**\u001b[38;5;28mself\u001b[39m.sp_model_kwargs)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.legacy \u001b[38;5;129;01mor\u001b[39;00m from_slow:  \u001b[38;5;66;03m# no dependency on protobuf\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocab_file, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001b[39m, in \u001b[36mSentencePieceProcessor.Load\u001b[39m\u001b[34m(self, model_file, model_proto)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[32m    960\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.LoadFromSerializedProto(model_proto)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001b[39m, in \u001b[36mSentencePieceProcessor.LoadFromFile\u001b[39m\u001b[34m(self, arg)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: not a string"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained('ChanceFocus/finma-7b-full')\n",
    "model = LlamaForCausalLM.from_pretrained('ChanceFocus/finma-7b-full', device_map='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7022d2-cf81-4179-8a92-6d358725fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7e5b6f-ef8c-4367-b317-7cf77f98c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177f5137-feef-4e61-ab91-f24a79238b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06d2e35-efd6-434a-af53-bbd557fea8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf85327-5710-437b-abd3-97b9d9dbb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C://Users//mhamu//Downloads//Assignment (1) (1)//Assignment//data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810d0b43-1cf2-4a81-9ae4-d064692eef25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Date</th>\n",
       "      <th>Invoice Number</th>\n",
       "      <th>Customer Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>Item Code</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BABU</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>SINBABU00133583</td>\n",
       "      <td>ABFIR004</td>\n",
       "      <td>FIRST PLACE (GUDU)</td>\n",
       "      <td>NBOMOATS16X350GPB</td>\n",
       "      <td>NUTRIBOM OATS 16X350G PB</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BABU</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>CCNBABU00005684</td>\n",
       "      <td>ABPER004</td>\n",
       "      <td>PER-VIN GLOBAL ENTERPRISES</td>\n",
       "      <td>HISTV43A4K</td>\n",
       "      <td>HIS TV 43 A4K FHD SMART</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BABU</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>SINBABU00133583</td>\n",
       "      <td>ABFIR004</td>\n",
       "      <td>FIRST PLACE (GUDU)</td>\n",
       "      <td>NBOMMULTIGR16X350GPB</td>\n",
       "      <td>NUTRIBOM MULTIGRAIN 16X350G PB</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BABU</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>SINBABU00133585</td>\n",
       "      <td>ABHME001</td>\n",
       "      <td>H-MEDIX PHARMACY LTD</td>\n",
       "      <td>LILYULTRASOFTNR10X12</td>\n",
       "      <td>ULTRA SOFT NORMAL SP 10x12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BABU</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>SINBABU00133583</td>\n",
       "      <td>ABFIR004</td>\n",
       "      <td>FIRST PLACE (GUDU)</td>\n",
       "      <td>NBOMMBANAPL16X350GPB</td>\n",
       "      <td>NUTRIBOM BANAN+APPLE16X350G PB</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site                 Date   Invoice Number Customer Code  \\\n",
       "0  BABU  2024-01-02 00:00:00  SINBABU00133583      ABFIR004   \n",
       "1  BABU  2024-01-02 00:00:00  CCNBABU00005684      ABPER004   \n",
       "2  BABU  2024-01-02 00:00:00  SINBABU00133583      ABFIR004   \n",
       "3  BABU  2024-01-02 00:00:00  SINBABU00133585      ABHME001   \n",
       "4  BABU  2024-01-02 00:00:00  SINBABU00133583      ABFIR004   \n",
       "\n",
       "                         Name             Item Code  \\\n",
       "0          FIRST PLACE (GUDU)     NBOMOATS16X350GPB   \n",
       "1  PER-VIN GLOBAL ENTERPRISES            HISTV43A4K   \n",
       "2          FIRST PLACE (GUDU)  NBOMMULTIGR16X350GPB   \n",
       "3        H-MEDIX PHARMACY LTD  LILYULTRASOFTNR10X12   \n",
       "4          FIRST PLACE (GUDU)  NBOMMBANAPL16X350GPB   \n",
       "\n",
       "                 Item Description  Quantity  \n",
       "0        NUTRIBOM OATS 16X350G PB       2.0  \n",
       "1         HIS TV 43 A4K FHD SMART      -1.0  \n",
       "2  NUTRIBOM MULTIGRAIN 16X350G PB      15.0  \n",
       "3      ULTRA SOFT NORMAL SP 10x12       1.0  \n",
       "4  NUTRIBOM BANAN+APPLE16X350G PB      10.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b408c603-a4eb-4d9c-abd6-401652af7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_texts = df.apply(lambda row: ' | '.join(row.astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044fdfa1-903e-4b62-9261-bfa136b70d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         BABU | 2024-01-02 00:00:00 | SINBABU00133583 |...\n",
       "1         BABU | 2024-01-02 00:00:00 | CCNBABU00005684 |...\n",
       "2         BABU | 2024-01-02 00:00:00 | SINBABU00133583 |...\n",
       "3         BABU | 2024-01-02 00:00:00 | SINBABU00133585 |...\n",
       "4         BABU | 2024-01-02 00:00:00 | SINBABU00133583 |...\n",
       "                                ...                        \n",
       "678020    SRAC | 2024-06-30 00:00:00 | SINSRAC00043495 |...\n",
       "678021    SRAC | 2024-06-30 00:00:00 | SINSRAC00043499 |...\n",
       "678022    SRAC | 2024-06-30 00:00:00 | SINSRAC00043500 |...\n",
       "678023    SWAR | 2024-06-30 00:00:00 | SINSWAR00038941 |...\n",
       "678024    SWAR | 2024-06-30 00:00:00 | SINSWAR00038943 |...\n",
       "Length: 678025, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24abf47a-c66c-445b-bd42-5d6f06278359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4035c0e9333640a9a10a0453c006b839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/21189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhamu\\enterprise_chatbot_fn\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 678025 rows, each of dimension (384,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a pre-trained Sentence Transformer modelfrom sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Generate embeddings for each row text\n",
    "embeddings = model.encode(row_texts, show_progress_bar=True)\n",
    "\n",
    "# embeddings is a list of numpy arrays representing each row as a vector\n",
    "print(f'Generated embeddings for {len(embeddings)} rows, each of dimension {embeddings[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f8028df-b312-404d-a9d1-2d61ff669529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (2.7.1+cu126)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (0.34.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d292017c-39c5-4d78-98ee-8e6628c6328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8a8c15-c54b-4d7e-a2c8-d1096293e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/google/sentencepiece#installation\n",
      "  Downloading https://github.com/google/sentencepiece\n",
      "     - 0 bytes ? 0:00:00\n",
      "     - 348.2 kB 10.9 MB/s 0:00:00\n",
      "     - 392.0 kB 12.3 MB/s 0:00:00\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Cannot unpack file C:\\Users\\mhamu\\AppData\\Local\\Temp\\pip-unpack-kayo7xsr\\sentencepiece (downloaded from C:\\Users\\mhamu\\AppData\\Local\\Temp\\pip-req-build-jdq42zd6, content-type: text/html; charset=utf-8); cannot detect archive format\n",
      "ERROR: Cannot determine archive format of C:\\Users\\mhamu\\AppData\\Local\\Temp\\pip-req-build-jdq42zd6\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/google/sentencepiece#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec304cb-37a3-4b73-b478-146db1b3cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Store embeddings in a vector database (e.g., FAISS)\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dimension = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)  # or other index types for large scale\n",
    "index.add(np.array(embeddings).astype('float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82ced0f-9bfe-4294-99db-b5ecf93cb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For each query, generate embedding\n",
    "query = \"What was the net profit for Q1 2024?\"\n",
    "query_embedding = model.encode([query])[0].astype('float32')\n",
    "\n",
    "# 4. Search for top k similar rows\n",
    "k = 5\n",
    "distances, indices = index.search(np.array([query_embedding]), k)\n",
    "\n",
    "# 5. Retrieve rows corresponding to indices and pass to an LLM for answer\n",
    "relevant_rows = [row_texts[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff1df0b3-27ad-4731-bc0c-8a8617478ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BHN3 | 2024-01-26 00:00:00 | SINHOLA00477025 | PAY001 | PAY POINTS INVESTING LTD (LA0456) | LGSPL15HPGENCOOL-B | LG SPLIT 1.5HP GENCOOL-B | 2.0',\n",
       " 'BHN3 | 2024-06-05 00:00:00 | SINHOLA00482600 | PAY001 | PAY POINTS INVESTING LTD (LA0456) | LGSPL15HPGENCOOL-B | LG SPLIT 1.5HP GENCOOL-B | 3.0',\n",
       " 'BHN3 | 2024-04-13 00:00:00 | SINHOLA00480367 | PAY001 | PAY POINTS INVESTING LTD (LA0456) | LGSPL10HPGENCOOL-B | LG SPLIT 1HP GENCOOL-B | 2.0',\n",
       " 'BHN6 | 2024-04-19 00:00:00 | SINHOLA00480613 | PAY001 | PAY POINTS INVESTING LTD (LA0456) | LGWM4V5RGPYJE | LG WM 4V5RGPYJE 10.5KG/7KG | 1.0',\n",
       " 'BHN3 | 2024-04-23 00:00:00 | SINHOLA00480729 | PAY001 | PAY POINTS INVESTING LTD (LA0456) | LGSPL10HPGENCOOL-B | LG SPLIT 1HP GENCOOL-B | 3.0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30612310-47c2-4bfc-b25b-00b364d6bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\mhamu\\enterprise_chatbot_fn\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.9 MB 393.8 kB/s eta 0:00:38\n",
      "    --------------------------------------- 0.3/14.9 MB 2.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/14.9 MB 3.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/14.9 MB 4.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/14.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/14.9 MB 5.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.9/14.9 MB 5.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.3/14.9 MB 5.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.7/14.9 MB 5.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.0/14.9 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.3/14.9 MB 6.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/14.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/14.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.3/14.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.8/14.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.3/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.9/14.9 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.2/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.8/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.2/14.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.4/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.7/14.9 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.0/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.3/14.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.7/14.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.9/14.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.2/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.5/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.7/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.1/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.4/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.7/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.1/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.4/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.7/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.1/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.7/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.0/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.3/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.7/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.0/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8c2fc-fb23-4abd-b00b-4c039544a909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f6904-6acb-4976-84fd-b18286990cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
